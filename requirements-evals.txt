# Requirements for local GPU evaluation with vLLM
# NOTE: Requires Python >=3.9,<3.13 (vLLM constraint)
# For Python 3.13+, use requirements-api.txt instead
# Note: 0.4.8 has a bug with --include_path task printing, use 0.4.9+
lm-eval==0.4.9
#torch==2.6.0
# flash_attn==2.7.4.post1
datasets<4
vllm==0.10.0
# for ifeval
langdetect
immutabledict
# antlr4